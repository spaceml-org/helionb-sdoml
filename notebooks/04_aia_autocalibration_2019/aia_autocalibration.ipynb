{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding the Capabilities of SDO: Autocalibration\n",
    "In this notebook, we demonstration the SDO Autocalibration model, as described in [Dos Santos et al., 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...648A..53D/abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luiz F. G. dos Santos, Souvik Bose, Valentina Salvatelli, Brad Neuberg, Mark C. M. Cheung, Miho Janvier, Meng Jin, Yarin Gal, Paul Boerner, Atılım Güneş Baydin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main dataset used for the project is the SDO ML dataset (see Galvez et al., 2019). For this notebook, we utilize a dataset that is not corrected for degradation, and is available from [Zenodo](https://zenodo.org/record/4430801#.X_xiP-lKhmE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is set out as follows:\n",
    "\n",
    "1. Setting up the notebook\n",
    "2. Reading and loading the SDO/AIA data\n",
    "3. Autocalibration Inference <br>\n",
    "    3a. Plotting <br>\n",
    "    3b. Single-channel Model\n",
    "3. Plotting the degradation curves\n",
    "4. Downloading & Correcting AIA images\n",
    "5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-00703c7fca8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "import astropy.time\n",
    "import torch\n",
    "import sunpy.map\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sdo.datasets.degradation_sdo_dataset import DegradationSDO_Dataset\n",
    "from sdo.pytorch_utilities import create_dataloader\n",
    "from sdo.models.autocalibration_models import Autocalibration6, Autocalibration10\n",
    "from astropy.visualization import time_support\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "from astropy.visualization import ImageNormalize, SqrtStretch, time_support\n",
    "from sunpy.net import Fido, attrs\n",
    "\n",
    "# from aiapy.calibrate import correct_degradation\n",
    "# from aiapy.calibrate.util import get_correction_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basedir = \"/media/paul/data/autocal_npz/data_small/\"\n",
    "data_inventory = \"/media/paul/data/autocal_npz/small_inventory.pkl\"\n",
    "results_path = \"/media/paul/data/autocal_npz/results/\"\n",
    "experiment_name = \"luiz_exp_36_apodize\"\n",
    "\n",
    "\n",
    "instr = [\"AIA\", \"AIA\", \"AIA\", \"AIA\", \"AIA\", \"AIA\", \"AIA\"]\n",
    "channels = [\"0094\", \"0131\", \"0171\", \"0193\", \"0211\", \"0304\", \"0335\"]\n",
    "channels_names = [\n",
    "    \"$94~\\AA$\",\n",
    "    \"$131~\\AA$\",\n",
    "    \"$171~\\AA$\",\n",
    "    \"$193~\\AA$\",\n",
    "    \"$211~\\AA$\",\n",
    "    \"$304~\\AA$\",\n",
    "    \"$335~\\AA$\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading and loading the SDO/AIA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/media/paul/data/autocal_npz/Models/luiz_exp_36_apodize_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DegradationSDO_Dataset(\n",
    "    data_basedir=data_basedir,\n",
    "    data_inventory=data_inventory,\n",
    "    instr=instr,\n",
    "    channels=channels,\n",
    "    yr_range=[2010, 2020],\n",
    "    mnt_step=1,\n",
    "    day_step=7,\n",
    "    h_step=1,\n",
    "    min_step=1,\n",
    "    resolution=512,\n",
    "    subsample=2,\n",
    "    normalization=0,\n",
    "    scaling=True,\n",
    "    apodize=True,\n",
    "    shuffle=False,\n",
    "    holdout=False,\n",
    "    test=True,\n",
    "    test_ratio=1,\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader(\n",
    "    test_dataset, batch_size=24, num_dataloader_workers=4, shuffle=False, train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step could potentially take a while\n",
    "\n",
    "model = Autocalibration6(input_shape=[7, 256, 256], output_dim=7)\n",
    "model.load_state_dict(\n",
    "    torch.load(model_file, map_location=torch.device(\"cuda\"))\n",
    ")  # need to use cuda if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autocalibration Inference\n",
    "### 3a. Multi-channel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input_data, dates) in enumerate(test_loader):\n",
    "        if batch_idx == 0:\n",
    "            output = model(input_data)\n",
    "            temp_degradation_multi = output\n",
    "            dates_multi_channel_array = np.array(dates)\n",
    "        else:\n",
    "            output = model(input_data)\n",
    "            temp_degradation_multi = torch.cat((temp_degradation_multi, output), 0)\n",
    "            dates_multi_channel_array = np.append(\n",
    "                dates_multi_channel_array, dates, axis=0\n",
    "            )\n",
    "\n",
    "degradation_multi_channel = temp_degradation_multi.detach().numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Loading the SDO data and making predictions using the Single-Channel model\n",
    "\n",
    "### It has two outputs: Seven degradation values \"single_degradation_total\" for all channels (this was ran in a loop, each time for one channel\" and seven dates \"dates_multi\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Single-channel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "degradation_single_channel = []\n",
    "dates_single_channel_array = []\n",
    "\n",
    "model_file = [\n",
    "    \"1000_luiz_exp_33_0094_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0131_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0171_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0193_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0211_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0304_masked_model.pth\",\n",
    "    \"1000_luiz_exp_33_0335_masked_model.pth\",\n",
    "]\n",
    "\n",
    "for c in range(len(channels)):\n",
    "    test_dataset = DegradationSDO_Dataset(\n",
    "        data_basedir=data_basedir,\n",
    "        data_inventory=data_inventory,\n",
    "        instr=[instr[c]],\n",
    "        channels=[channels[c]],\n",
    "        yr_range=[2010, 2020],\n",
    "        mnt_step=1,\n",
    "        day_step=7,\n",
    "        h_step=1,\n",
    "        min_step=1,\n",
    "        resolution=512,\n",
    "        subsample=2,\n",
    "        normalization=0,\n",
    "        scaling=True,\n",
    "        apodize=True,\n",
    "        shuffle=False,\n",
    "        holdout=False,\n",
    "        test_ratio=1,\n",
    "        test=True,\n",
    "    )\n",
    "\n",
    "    test_loader = create_dataloader(\n",
    "        test_dataset,\n",
    "        batch_size=128,\n",
    "        num_dataloader_workers=8,\n",
    "        shuffle=False,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    model = Autocalibration6(input_shape=[1, 256, 256], output_dim=1)\n",
    "    model.load_state_dict(\n",
    "        torch.load(\n",
    "            \"/home/paul/Documents/SpaceML/sdoml_data/Models/\" + model_file[c],\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    final_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_data, dates) in enumerate(test_loader):\n",
    "            if batch_idx == 0:\n",
    "                output = model(input_data)\n",
    "                temp_degradation_single = output\n",
    "                temp_dates_single = np.array(dates)\n",
    "            else:\n",
    "                output = model(input_data)\n",
    "                temp_degradation_single = torch.cat(\n",
    "                    (temp_degradation_single, output), 0\n",
    "                )\n",
    "                temp_dates_single = np.append(temp_dates_single, dates, axis=0)\n",
    "\n",
    "    temp_degradation_single = temp_degradation_single.detach().numpy()\n",
    "    degradation_single_channel.append(temp_degradation_single)\n",
    "    dates_single_channel_array.append(temp_dates_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all times to astropy time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve_date = [\"20140526\", \"20140526\"]  # LasMAriah it date with EVE MEGS-A data.\n",
    "last_training_date = [\"20131231\", \"20131231\"]  # Last date with EVE MEGS-A data.\n",
    "xticks = [\n",
    "    \"20100101\",\n",
    "    \"20110101\",\n",
    "    \"20120101\",\n",
    "    \"20130101\",\n",
    "    \"20140101\",\n",
    "    \"20150101\",\n",
    "    \"20160101\",\n",
    "    \"20170101\",\n",
    "    \"20180101\",\n",
    "    \"20190101\",\n",
    "    \"20200101\",\n",
    "]\n",
    "\n",
    "dates_multi_channel_str = list(\n",
    "    map(\n",
    "        \"{:4d}{:02d}{:02d}{:02d}{:02d}\".format,\n",
    "        dates_multi_channel_array[:, 0],\n",
    "        dates_multi_channel_array[:, 1],\n",
    "        dates_multi_channel_array[:, 2],\n",
    "        dates_multi_channel_array[:, 3],\n",
    "        dates_multi_channel_array[:, 4],\n",
    "    )\n",
    ")\n",
    "\n",
    "dates_multi = [\n",
    "    datetime.datetime.strptime(i, \"%Y%m%d%H%M\").date() for i in dates_multi_channel_str\n",
    "]\n",
    "dates_multi = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in dates_multi])\n",
    "\n",
    "eve_line = [datetime.datetime.strptime(i, \"%Y%m%d\").date() for i in eve_date]\n",
    "eve_line = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in eve_line])\n",
    "\n",
    "last_training_line = [\n",
    "    datetime.datetime.strptime(i, \"%Y%m%d\").date() for i in last_training_date\n",
    "]\n",
    "last_training_line = astropy.time.Time(\n",
    "    [astropy.time.Time(i.isoformat()) for i in last_training_line]\n",
    ")\n",
    "\n",
    "xticks = [datetime.datetime.strptime(i, \"%Y%m%d\").date() for i in xticks]\n",
    "xticks = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in xticks])\n",
    "\n",
    "dates_single = []\n",
    "for c in range(len(channels)):\n",
    "    dates_single_channel_str = list(\n",
    "        map(\n",
    "            \"{:4d}{:02d}{:02d}\".format,\n",
    "            dates_single_channel_array[c][:, 0],\n",
    "            dates_single_channel_array[c][:, 1],\n",
    "            dates_single_channel_array[c][:, 2],\n",
    "        )\n",
    "    )\n",
    "    temp = [\n",
    "        datetime.datetime.strptime(i, \"%Y%m%d\").date() for i in dates_single_channel_str\n",
    "    ]  # x_values for 0094\n",
    "    temp = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in temp])\n",
    "    dates_single.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining two fuctions to use as a median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_median(dates):\n",
    "    median = math.floor(np.median(dates.astype(\"int64\")))\n",
    "    result = np.datetime64(median, \"ns\")  # unit: nanosecond\n",
    "    return result\n",
    "\n",
    "\n",
    "def moving_median(data, dates, window):\n",
    "    iti = int(np.floor(data.shape[0] / window))\n",
    "    median = []\n",
    "    date = []\n",
    "\n",
    "    for i in range(iti - 1):\n",
    "        median.append(np.median(data[(i * window) : ((i + 1) * window)]))\n",
    "        date.append(date_median(dates[(i * window) : ((i + 1) * window)]))\n",
    "\n",
    "    return np.array(median, dtype=\"float64\"), pd.to_datetime(date)\n",
    "\n",
    "\n",
    "def moving_std(data, dates, window):\n",
    "    iti = int(np.floor(data.shape[0] / window))\n",
    "    std = []\n",
    "\n",
    "    for i in range(iti):\n",
    "        std.append(np.std(data[(i * window) : ((i + 1) * window)]))\n",
    "\n",
    "    return np.array(std, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plotting the Degradation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v9dat = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# v9dat = pd.read_csv('/media/paul/data/autocal_npz/data_v8_ratios.csv', parse_dates=True,\n",
    "#                    names=[\"DATE\"] + channels, index_col=\"DATE\",skiprows=1, header=0) #Reading the degradations obtained from AIApy for curve V9\n",
    "v8dat = pd.read_csv(\n",
    "    \"/media/paul/data/autocal_npz/data_v8table.csv\",\n",
    "    parse_dates=True,\n",
    "    names=[\"DATE\"] + channels,\n",
    ")  # Reading the degradations obtained from AIApy for curve V8\n",
    "\n",
    "v8dat[\"DATE\"].replace(\n",
    "    \"Z\", \".000\", regex=True, inplace=True\n",
    ")  # Fixing some inconsistent data formating\n",
    "v8dat[\"DATE\"] = pd.to_datetime(v8dat[\"DATE\"], infer_datetime_format=True)\n",
    "v8dat.set_index(\"DATE\", inplace=True)\n",
    "\n",
    "time_support()  # Adding support of Astropy date to plot.\n",
    "colors = [\"Blue\", \"Orange\", \"Green\", \"Red\", \"Purple\", \"Brown\", \"Magenta\"]\n",
    "\n",
    "fig, ax = plt.subplots(4, 2, figsize=(17, 22), dpi=300)\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.18)\n",
    "ax = ax.ravel()\n",
    "\n",
    "for c in range(len(channels)):\n",
    "    # v9dat[channels[c]] = v9dat[channels[c]].astype(np.float64)\n",
    "    v8dat[channels[c]] = v8dat[channels[c]].astype(np.float64)\n",
    "\n",
    "    # v9dat[channels[c]] = v9dat[channels[c]]/v9dat[channels[c]][0]\n",
    "    v8dat[channels[c]] = v8dat[channels[c]] / v8dat[channels[c]][0]\n",
    "    # v9med_data, v9med_dates = moving_median(v9dat[channels[c]],v9dat.index,28)\n",
    "    v8med_data, v8med_dates = moving_median(v8dat[channels[c]], v8dat.index, 28)\n",
    "\n",
    "    multi_med_data, multi_med_dates = moving_median(\n",
    "        degradation_multi_channel[:, c], pd.DataFrame(dates_multi.tt.datetime), 15\n",
    "    )\n",
    "    multi_std_data = moving_std(\n",
    "        degradation_multi_channel[:, c], pd.DataFrame(dates_multi.tt.datetime), 15\n",
    "    )\n",
    "    single_med_data, single_med_dates = moving_median(\n",
    "        degradation_single_channel[c], pd.DataFrame(dates_single[c].tt.datetime), 15\n",
    "    )\n",
    "    single_std_data = moving_std(\n",
    "        degradation_single_channel[c], pd.DataFrame(dates_single[c].tt.datetime), 15\n",
    "    )\n",
    "\n",
    "    # euv_v9_times = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in v9med_dates])\n",
    "    euv_v8_times = astropy.time.Time(\n",
    "        [astropy.time.Time(i.isoformat()) for i in v8med_dates]\n",
    "    )\n",
    "    multi_med_times = astropy.time.Time(\n",
    "        [astropy.time.Time(i.isoformat()) for i in multi_med_dates]\n",
    "    )\n",
    "    single_med_times = astropy.time.Time(\n",
    "        [astropy.time.Time(i.isoformat()) for i in single_med_dates]\n",
    "    )\n",
    "\n",
    "    ax[c].fill_between(\n",
    "        dates_multi[0:209],\n",
    "        1.5,\n",
    "        0,\n",
    "        color=colors[c],\n",
    "        label=\"Training data period\",\n",
    "        alpha=0.05,\n",
    "    )\n",
    "    ax[c].plot(\n",
    "        last_training_line, [0, 2], \"--\", color=\"black\", label=\"Last Training date\"\n",
    "    )\n",
    "    ax[c].plot(eve_line, [0, 2], \"--\", color=\"gray\", label=\"Last EVE MEGS-A data\")\n",
    "    ax[c].plot(\n",
    "        multi_med_times,\n",
    "        multi_med_data,\n",
    "        label=channels_names[c] + \" - Multi-Channel\",\n",
    "        linewidth=2,\n",
    "        color=colors[c],\n",
    "    )\n",
    "    ax[c].plot(\n",
    "        single_med_times,\n",
    "        single_med_data,\n",
    "        \"--\",\n",
    "        label=channels_names[c] + \" - Single-Channel\",\n",
    "        linewidth=2,\n",
    "        color=colors[c],\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    # ax[c].plot(euv_v9_times, v9med_data, color='black',\\\n",
    "    #           label=channels_names[c]+' - Degradation V9', linewidth=3, alpha=0.9)\n",
    "    ax[c].plot(\n",
    "        euv_v8_times,\n",
    "        v8med_data,\n",
    "        color=\"gray\",\n",
    "        label=channels_names[c] + \" - Degradation V8\",\n",
    "        linewidth=3,\n",
    "        alpha=0.9,\n",
    "    )\n",
    "\n",
    "    # up = [m + n for m, n in zip(v9med_data, v9med_data*0.28)]\n",
    "    up_multi = [m + n for m, n in zip(multi_med_data, multi_std_data)]\n",
    "    up_single = [m + n for m, n in zip(single_med_data, single_std_data)]\n",
    "    # down = [m - n for m, n in zip(v9med_data,v9med_data*0.28)]\n",
    "    down_multi = [m - n for m, n in zip(multi_med_data, multi_std_data)]\n",
    "    down_single = [m - n for m, n in zip(single_med_data, single_std_data)]\n",
    "\n",
    "    # ax[c].fill_between(euv_v9_times,up,down,color='gray', alpha=0.1)\n",
    "    ax[c].fill_between(\n",
    "        multi_med_times,\n",
    "        up_multi,\n",
    "        down_multi,\n",
    "        color=colors[c],\n",
    "        label=\"Standard Deviation\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    ax[c].fill_between(\n",
    "        single_med_times, up_single, down_single, color=colors[c], alpha=0.1\n",
    "    )\n",
    "\n",
    "    if c % 2 == 0:\n",
    "        ax[c].set_ylabel(\"Degradation\", fontsize=14)\n",
    "\n",
    "    ax[c].set_xlabel(\"Time (UTC)\", fontsize=14)\n",
    "    plt.xticks(np.arange(0, 4), fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax[c].legend(fontsize=10)\n",
    "    ax[c].set_ylim(0, 1.05)\n",
    "    ax[c].set_xlim(multi_med_times[0] - 1, multi_med_times[-1])\n",
    "\n",
    "ax[c + 1].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocal_table = []\n",
    "\n",
    "for i in range(0, len(dates_multi_channel_array)):\n",
    "    d = {\n",
    "        **{\"DATE\": dates_multi.tt.datetime[i]},\n",
    "        **{\n",
    "            channels[n]: degradation_multi_channel[i][n]\n",
    "            for n in range(len(degradation_multi_channel[i]))\n",
    "        },\n",
    "    }\n",
    "    my_df.append(d)\n",
    "\n",
    "autocal_table = pd.DataFrame(autocal_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Downloading & Correcting AIA images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will obtain AIA images from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During testing Fido.search returned zero results when requesting 1 image a year for 10 years.\n",
    "# This is now done in two chunks.\n",
    "\n",
    "q_one = Fido.search(\n",
    "    attrs.Time(\"2010-06-01T00:00:00\", \"2015-01-02T00:00:00\"),\n",
    "    attrs.Sample(1 * u.year),\n",
    "    attrs.Instrument(\"AIA\"),\n",
    "    attrs.Wavelength(304 * u.angstrom),\n",
    ")\n",
    "\n",
    "q_two = Fido.search(\n",
    "    attrs.Time(\"2016-06-01T00:00:00\", \"2020-01-01T00:00:00\"),\n",
    "    attrs.Sample(1 * u.year),\n",
    "    attrs.Instrument(\"AIA\"),\n",
    "    attrs.Wavelength(304 * u.angstrom),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_one = Fido.fetch(q_one)\n",
    "files_two = Fido.fetch(q_two)\n",
    "all_files = files_one + files_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_degradation(smap, table):\n",
    "    \"\"\"\n",
    "    Correct degradation using time-step in the correction table that is closest to the observation date.\n",
    "    \"\"\"\n",
    "    index = (\n",
    "        table[\"DATE\"]\n",
    "        .sub(pd.to_datetime(smap.date.value, infer_datetime_format=True))\n",
    "        .abs()\n",
    "        .idxmin()\n",
    "    )\n",
    "    num = smap.meta[\"wavelnth\"]\n",
    "    return smap._new_instance(\n",
    "        smap.data / table.iloc[index][f\"{int(num):04}\"], smap.meta\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = sunpy.map.Map(sorted(all_files))\n",
    "maps_corrected = [correct_degradation(m, autocal_table) for m in maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the image normalisation constant across the images\n",
    "norm = ImageNormalize(vmin=0, vmax=4e2, stretch=SqrtStretch())\n",
    "\n",
    "fig = plt.figure(figsize=(len(maps) * 3, 6))\n",
    "plt.subplots_adjust(wspace=-0.2, hspace=0)\n",
    "\n",
    "for i, (m, mc) in enumerate(zip(maps, maps_corrected)):\n",
    "    ax = fig.add_subplot(2, len(maps), i + 1, projection=m)\n",
    "    m.plot(axes=ax, norm=norm, annotate=False)\n",
    "    ax.set_title(m.date.datetime.year)\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"uncorrected\")\n",
    "\n",
    "    ax = fig.add_subplot(2, len(maps), i + 1 + len(maps), projection=mc)\n",
    "    mc.plot(axes=ax, norm=norm, annotate=False)\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    ax.set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
