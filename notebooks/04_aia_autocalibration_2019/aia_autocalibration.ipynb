{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding the Capabilities of SDO: SDO/AIA Autocalibration\n",
    "In this notebook, we demonstrate the SDO Autocalibration model, as described in [Dos Santos et al., 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...648A..53D/abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luiz F. G. dos Santos, Souvik Bose, Valentina Salvatelli, Brad Neuberg, Mark C. M. Cheung, Miho Janvier, Meng Jin, Yarin Gal, Paul Boerner, Atılım Güneş Baydin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it launch in 2010, the Solar Dynamics Observatory (SDO) has continually monitored the dynamic Sun. SDO observes over a range of wavelengths including the Extreme ultraviolet (EUV), which allows us to probe the dynamics of the outermost layers of the Sun: the chromosphere and corona\n",
    "\n",
    "Unfortunately, EUV imagers suffer from time-dependent degradation of the EUV filters. This reduces their sensitivity, and is observed as an apparent decrease in total flux as a function of time. For SDO, sounding rocket flights have been used to periodically calibrate the Atmospheric Imaging Assembly (AIA). The time-dependent degradation curves for AIA are then derived by interpolated between subsequent flights. \n",
    "\n",
    "In this notebook we perform inference on the convolutional neural network model by [Dos Santos et al., 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...648A..53D/abstract), to first extract the degradation curves, and then correct a set of images over 10 years of observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B:** *The main dataset used for the project is the SDO ML dataset (see [Galvez et al., 2019](https://ui.adsabs.harvard.edu/abs/2019ApJS..242....7G/abstract)). For this notebook, we utilize a dataset that is not corrected for degradation, and is available from [Zenodo](https://zenodo.org/record/4430801#.X_xiP-lKhmE).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook is set out as follows:\n",
    "\n",
    "1. Setting up the notebook\n",
    "2. Reading and loading the SDO/AIA data\n",
    "3. Autocalibration Inference <br>\n",
    "    3a. Multi-channel Model <br>\n",
    "3. Plotting the degradation curves\n",
    "4. Downloading & Correcting AIA images\n",
    "5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import astropy.time\n",
    "import sunpy.map\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "\n",
    "from sdo.datasets.degradation_sdo_dataset import DegradationSDO_Dataset\n",
    "from sdo.pytorch_utilities import create_dataloader\n",
    "from sdo.models.autocalibration_models import Autocalibration6, Autocalibration10\n",
    "from astropy.visualization import time_support\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "from astropy.visualization import ImageNormalize, LogStretch, SqrtStretch, time_support\n",
    "from sunpy.net import Fido, attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_basedir = 'data_small'\n",
    "data_inventory = 'small_inventory.pkl'\n",
    "\n",
    "instr = ['AIA']*7\n",
    "channels = ['0094','0131','0171','0193','0211','0304','0335']\n",
    "channels_names = ['$94~\\AA$','$131~\\AA$','$171~\\AA$','$193~\\AA$','$211~\\AA$','$304~\\AA$','$335~\\AA$']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading and loading the SDO/AIA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'Models/luiz_exp_36_apodize_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DegradationSDO_Dataset(data_basedir = data_basedir,\n",
    "                                    data_inventory = data_inventory,\n",
    "                                    instr = instr,\n",
    "                                    channels = channels,\n",
    "                                    yr_range = [2010,2021],\n",
    "                                    mnt_step = 1,\n",
    "                                    day_step = 7,\n",
    "                                    h_step = 1,\n",
    "                                    min_step = 1,\n",
    "                                    resolution = 512,\n",
    "                                    subsample = 2,\n",
    "                                    normalization = 0, \n",
    "                                    scaling = True,\n",
    "                                    apodize = True,\n",
    "                                    shuffle = False,\n",
    "                                    holdout = False,\n",
    "                                    test = True,\n",
    "                                    test_ratio = 1)\n",
    "\n",
    "test_loader = create_dataloader(test_dataset, batch_size=24, num_dataloader_workers=4, shuffle=False, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this step could potentially take a while\n",
    "\n",
    "model = Autocalibration6(input_shape=[7, 256, 256], output_dim=7)\n",
    "model.load_state_dict(torch.load(model_file,map_location=torch.device('cuda'))) # need to use cuda if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Autocalibration Inference\n",
    "\n",
    "In [Dos Santos et al., 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...648A..53D/abstract), two models were tested: a multi-channel model, and a single-channel model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Multi-channel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (input_data, dates) in enumerate(test_loader):\n",
    "        if batch_idx==0:\n",
    "            output = model(input_data)\n",
    "            temp_degradation_multi = output\n",
    "            dates_multi_channel_array = np.array(dates)\n",
    "        else:\n",
    "            output = model(input_data)\n",
    "            temp_degradation_multi = torch.cat((temp_degradation_multi, output), 0)\n",
    "            dates_multi_channel_array = np.append(dates_multi_channel_array,dates,axis=0) \n",
    "\n",
    "degradation_multi_channel = temp_degradation_multi.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all times to astropy time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve_date = ['20140526','20140526'] #Last date with EVE MEGS-A data.\n",
    "last_training_date = ['20131231','20131231'] #Last date with EVE MEGS-A data.\n",
    "xticks = ['20100101','20110101','20120101','20130101','20140101','20150101','20160101','20170101','20180101','20190101','20200101',]\n",
    "\n",
    "dates_multi_channel_str = list(map('{:4d}{:02d}{:02d}{:02d}{:02d}'.format,dates_multi_channel_array[:,0],dates_multi_channel_array[:,1],dates_multi_channel_array[:,2],dates_multi_channel_array[:,3],dates_multi_channel_array[:,4]))\n",
    "\n",
    "dates_multi = [datetime.datetime.strptime(i,\"%Y%m%d%H%M\").date() for i in dates_multi_channel_str]\n",
    "dates_multi = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in dates_multi])\n",
    "\n",
    "eve_line = [datetime.datetime.strptime(i,\"%Y%m%d\").date() for i in eve_date]\n",
    "eve_line = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in eve_line])\n",
    "\n",
    "last_training_line = [datetime.datetime.strptime(i,\"%Y%m%d\").date() for i in last_training_date]\n",
    "last_training_line = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in last_training_line])\n",
    "\n",
    "xticks = [datetime.datetime.strptime(i,\"%Y%m%d\").date() for i in xticks]\n",
    "xticks = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in xticks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining two fuctions to use as a median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_median(dates):\n",
    "    median = math.floor(np.median(dates.astype('int64')))\n",
    "    result = np.datetime64(median, \"ns\") #unit: nanosecond\n",
    "    return result\n",
    "\n",
    "def moving_median(data,dates,window):\n",
    "    iti = int(np.floor(data.shape[0]/window))\n",
    "    median = []\n",
    "    date = []\n",
    "    \n",
    "    for i in range(iti-1):\n",
    "        median.append(np.median(data[(i*window):((i+1)*window)]))\n",
    "        date.append(date_median(dates[(i*window):((i+1)*window)]))\n",
    "        \n",
    "    return np.array(median, dtype='float64'), pd.to_datetime(date)\n",
    "\n",
    "def moving_std(data,dates,window):\n",
    "    iti = int(np.floor(data.shape[0]/window))\n",
    "    std = []    \n",
    "\n",
    "    for i in range(iti):\n",
    "        std.append(np.std(data[(i*window):((i+1)*window)]))\n",
    "                \n",
    "    return np.array(std, dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plotting the Degradation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "v8dat = pd.read_csv('data_v8table.csv', parse_dates=True,\n",
    "                    names=[\"DATE\"] + channels) #Reading the degradations obtained from AIApy for curve V8\n",
    "\n",
    "v8dat['DATE'].replace('Z', '.000',regex=True,inplace=True) #Fixing some inconsistent data formating\n",
    "v8dat['DATE'] = pd.to_datetime(v8dat['DATE'], infer_datetime_format=True)\n",
    "v8dat.set_index('DATE', inplace=True)\n",
    "\n",
    "time_support()  #Adding support of Astropy date to plot.\n",
    "colors = ['Blue','Orange','Green','Red','Purple','Brown','Magenta']\n",
    "\n",
    "fig, ax = plt.subplots(4, 2, figsize=(17,22), dpi=300)\n",
    "fig.subplots_adjust(wspace=0.1,hspace=0.18)\n",
    "ax = ax.ravel()    \n",
    "\n",
    "for c in range(len(channels)):\n",
    "    v8dat[channels[c]] = v8dat[channels[c]].astype(np.float64)\n",
    "\n",
    "    v8dat[channels[c]] = v8dat[channels[c]]/v8dat[channels[c]][0]\n",
    "    v8med_data, v8med_dates = moving_median(v8dat[channels[c]],v8dat.index,28)\n",
    "\n",
    "    multi_med_data, multi_med_dates = moving_median(degradation_multi_channel[:,c],pd.DataFrame(dates_multi.tt.datetime),15)\n",
    "    multi_std_data = moving_std(degradation_multi_channel[:,c],pd.DataFrame(dates_multi.tt.datetime),15)\n",
    "    \n",
    "    euv_v8_times = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in v8med_dates])\n",
    "    multi_med_times = astropy.time.Time([astropy.time.Time(i.isoformat()) for i in multi_med_dates])\n",
    "\n",
    "    ax[c].fill_between(dates_multi[0:209],1.5,0,color=colors[c],label='Training data period', alpha=0.05)\n",
    "    ax[c].plot(last_training_line,[0,2], '--', color='black', label='Last Training date')\n",
    "    ax[c].plot(eve_line,[0,2], '--', color='gray', label='Last EVE MEGS-A data')\n",
    "    ax[c].plot(multi_med_times, multi_med_data, \\\n",
    "               label=channels_names[c]+' - Multi-Channel',linewidth=2,color=colors[c])\n",
    "    ax[c].plot(euv_v8_times, v8med_data, color='gray',\\\n",
    "               label=channels_names[c]+' - Degradation V8', linewidth=3, alpha=0.9)\n",
    "    \n",
    "    up_multi = [m + n for m,n in zip(multi_med_data,multi_std_data)]\n",
    "    down_multi = [m - n for m,n in zip(multi_med_data,multi_std_data)]\n",
    "\n",
    "    ax[c].fill_between(multi_med_times,up_multi,down_multi,color=colors[c], label='Standard Deviation', alpha=0.1)\n",
    "\n",
    "    if c%2 == 0:\n",
    "        ax[c].set_ylabel('Degradation',fontsize=14)\n",
    "    \n",
    "    ax[c].set_xlabel('Time (UTC)',fontsize=14)\n",
    "    plt.xticks(np.arange(0,4),fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    ax[c].legend(fontsize=10)\n",
    "    ax[c].set_ylim(0,1.05)\n",
    "    ax[c].set_xlim(multi_med_times[0]-1,multi_med_times[-1])\n",
    "\n",
    "ax[c+1].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**: Channel degradation as a function of time. From top to bottom: Channel 94 Å (blue) and 131 Å (yellow), 171Å (green) and 193 Å (red), 211 Å (purple) and 304 Å (brown) and 335 Å (magenta). The solid black (gray) curve is the degradation profile of AIA calibration release V9 (V8). The gray shaded area corresponds to the 25% error of the degradation curve (V9). The colorful shaded areas are the standard deviation of the CNN models.The vertical black dashed line is the last available observation from EVE MEGS-A data and the vertical gray dashed line is the last training date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Downloading & Correcting AIA images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the AIA Autocalibration correction table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocal_table = []\n",
    "\n",
    "for i in range(0,len(dates_multi_channel_array)):\n",
    "    d = {\n",
    "        **{'DATE' : dates_multi.tt.datetime[i]},\n",
    "        **{channels[n]: degradation_multi_channel[i][n] for n in range(len(degradation_multi_channel[i]))}\n",
    "    }\n",
    "    autocal_table.append(d)\n",
    "\n",
    "autocal_table = pd.DataFrame(autocal_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will directly query Stanford's Joint Science Operations Crnter (JSOC). Alternatively, one could also use Fido, as part of SunPy, however, in testing, queries on such extreme time-sclaes resulted in varying levels of success:\n",
    "\n",
    "```\n",
    "files = []\n",
    "\n",
    "query = Fido.search(\n",
    "    attrs.Time(f'2010-06-01T00:00:00', f'2020-07-01T01:00:00'),\n",
    "    attrs.Sample(30*u.min),\n",
    "    attrs.Instrument('AIA'),\n",
    "    attrs.Wavelength(304*u.angstrom),\n",
    ")\n",
    "\n",
    "dn =Fido.fetch(query[0][0])\n",
    "files.append(dn[0])\n",
    "    \n",
    "maps = sunpy.map.Map(files)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drms\n",
    "email = 'paul@wrightai.com'\n",
    "c = drms.Client(debug=True, verbose=True, email=email)\n",
    "r = c.export('aia.lev1_euv_12s[2010.06.01/4000d@365d][304]{image}', method='url', protocol='fits')\n",
    "maps = sunpy.map.Map(sorted(r.urls['url']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have observations, we need to correct these for degradation. We will query the closest degradation value in the autocal table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_degradation(smap, table):\n",
    "    \"\"\"\n",
    "    Correct degradation using time-step in the correction table that is closest to the observation date.\n",
    "    \"\"\"\n",
    "    index = table['DATE'].sub(pd.to_datetime(smap.date.value, infer_datetime_format=True)).abs().idxmin()\n",
    "    num = smap.meta['wavelnth']\n",
    "    return smap._new_instance(smap.data / table.iloc[index][f'{int(num):04}'], smap.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps_corrected = [correct_degradation(m, autocal_table) for m in maps]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We set the image normalisation constant across the images\n",
    "norm = ImageNormalize(vmin=0, vmax=1e3, stretch=LogStretch(100))\n",
    "\n",
    "fig = plt.figure(figsize=(len(maps)*3, 6))\n",
    "plt.subplots_adjust(wspace=-.2, hspace=0)\n",
    "\n",
    "for i, (m, mc) in enumerate(zip(maps, maps_corrected)):\n",
    "    ax = fig.add_subplot(2, len(maps), i+1, projection=m)\n",
    "    m.plot(axes=ax, norm=norm, annotate=False)\n",
    "    ax.set_title(m.date.datetime.year)\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    ax.set_aspect('equal')\n",
    "        \n",
    "    ax = fig.add_subplot(2, len(maps), i+1+len(maps), projection=mc)\n",
    "    mc.plot(axes=ax, norm=norm, annotate=False)\n",
    "    ax.coords[0].set_ticks_visible(False)\n",
    "    ax.coords[0].set_ticklabel_visible(False)\n",
    "    ax.coords[1].set_ticks_visible(False)\n",
    "    ax.coords[1].set_ticklabel_visible(False)\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3:** *Top*: Yearly observations of SDO/AIA 304 A data as observed by SDO/AIA, plotted on the same scale. *Bottom*: As top, but with corrected for time-dependent degradation using the AIA Autocalibration method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
